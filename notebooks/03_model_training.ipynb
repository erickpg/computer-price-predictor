{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Model Training: Computer Price Prediction\n",
    "\n",
    "This notebook trains and evaluates models to predict computer prices.\n",
    "\n",
    "**Models compared:**\n",
    "1. Baseline (DummyRegressor - predicts mean)\n",
    "2. RandomForestRegressor\n",
    "3. HistGradientBoostingRegressor\n",
    "4. CatBoostRegressor (with native categorical handling)\n",
    "5. CatBoost Quantile models (for price range prediction)\n",
    "\n",
    "**Metrics:**\n",
    "- RMSE (primary)\n",
    "- MAE\n",
    "- R²\n",
    "- MAPE\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Reload modeling module\n",
    "for mod in ['src.modeling', 'modeling']:\n",
    "    if mod in sys.modules:\n",
    "        del sys.modules[mod]\n",
    "\n",
    "from src.modeling import (\n",
    "    infer_feature_types,\n",
    "    get_feature_summary,\n",
    "    build_sklearn_pipeline,\n",
    "    build_catboost_model,\n",
    "    prepare_catboost_data,\n",
    "    evaluate_sklearn_cv,\n",
    "    evaluate_predictions,\n",
    "    compare_models,\n",
    "    save_model,\n",
    "    load_features_data,\n",
    "    CATBOOST_AVAILABLE\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "sns.set_theme(style='whitegrid')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded!\")\n",
    "print(f\"CatBoost available: {CATBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "\n",
    "# Try to load parquet, fall back to CSV\n",
    "try:\n",
    "    df = pd.read_parquet(DATA_DIR / 'db_features.parquet')\n",
    "    print(\"Loaded from parquet\")\n",
    "except (ImportError, FileNotFoundError):\n",
    "    df = pd.read_csv(DATA_DIR / 'db_features.csv')\n",
    "    print(\"Loaded from CSV\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable\n",
    "TARGET_COL = '_precio_num'\n",
    "\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"  Non-null: {df[TARGET_COL].notna().sum():,}\")\n",
    "print(f\"  Min: {df[TARGET_COL].min():,.2f}\")\n",
    "print(f\"  Max: {df[TARGET_COL].max():,.2f}\")\n",
    "print(f\"  Mean: {df[TARGET_COL].mean():,.2f}\")\n",
    "print(f\"  Median: {df[TARGET_COL].median():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Prepare Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer feature types automatically\n",
    "feature_cols, numeric_cols, categorical_cols = infer_feature_types(df, TARGET_COL)\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"  Numeric: {len(numeric_cols)}\")\n",
    "print(f\"  Categorical: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature summary\n",
    "summary = get_feature_summary(df, numeric_cols, categorical_cols)\n",
    "\n",
    "print(\"=== Numeric Features ===\")\n",
    "display(summary[summary['type'] == 'numeric'].head(20))\n",
    "\n",
    "print(\"\\n=== Categorical Features (sample) ===\")\n",
    "display(summary[summary['type'] == 'categorical'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df[feature_cols].copy()\n",
    "y = df[TARGET_COL].copy()\n",
    "\n",
    "# Remove rows with missing target\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"Training data shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} samples\")\n",
    "print(f\"Test: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Models\n",
    "\n",
    "We'll train multiple models and compare their performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Model (DummyRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BASELINE MODEL (Predict Mean)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_pipeline = build_sklearn_pipeline('dummy', numeric_cols, categorical_cols)\n",
    "baseline_results = evaluate_sklearn_cv(baseline_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['Baseline (Mean)'] = baseline_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {baseline_results['rmse_mean']:,.2f} (+/- {baseline_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {baseline_results['mae_mean']:,.2f} (+/- {baseline_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {baseline_results['r2_mean']:.4f} (+/- {baseline_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf_pipeline = build_sklearn_pipeline('random_forest', numeric_cols, categorical_cols)\n",
    "rf_results = evaluate_sklearn_cv(rf_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['Random Forest'] = rf_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {rf_results['rmse_mean']:,.2f} (+/- {rf_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {rf_results['mae_mean']:,.2f} (+/- {rf_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {rf_results['r2_mean']:.4f} (+/- {rf_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### 4.3 HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HIST GRADIENT BOOSTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hgb_pipeline = build_sklearn_pipeline('hist_gradient_boosting', numeric_cols, categorical_cols)\n",
    "hgb_results = evaluate_sklearn_cv(hgb_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['HistGradientBoosting'] = hgb_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {hgb_results['rmse_mean']:,.2f} (+/- {hgb_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {hgb_results['mae_mean']:,.2f} (+/- {hgb_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {hgb_results['r2_mean']:.4f} (+/- {hgb_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "### 4.4 CatBoost (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CATBOOST_AVAILABLE:\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from catboost import CatBoostRegressor\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CATBOOST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Prepare data for CatBoost\n",
    "    X_cb, y_cb = prepare_catboost_data(\n",
    "        df[mask].copy(),\n",
    "        numeric_cols,\n",
    "        categorical_cols,\n",
    "        TARGET_COL\n",
    "    )\n",
    "    \n",
    "    X_cb_train, X_cb_test, y_cb_train, y_cb_test = train_test_split(\n",
    "        X_cb, y_cb, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Build CatBoost model\n",
    "    cat_model = build_catboost_model(categorical_cols, loss_function='RMSE')\n",
    "    \n",
    "    # Cross-validation using sklearn\n",
    "    neg_rmse_scores = cross_val_score(\n",
    "        cat_model, X_cb_train, y_cb_train, \n",
    "        cv=5, scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "    neg_mae_scores = cross_val_score(\n",
    "        cat_model, X_cb_train, y_cb_train,\n",
    "        cv=5, scoring='neg_mean_absolute_error'\n",
    "    )\n",
    "    r2_scores = cross_val_score(\n",
    "        cat_model, X_cb_train, y_cb_train,\n",
    "        cv=5, scoring='r2'\n",
    "    )\n",
    "    \n",
    "    cat_results = {\n",
    "        'rmse_mean': -neg_rmse_scores.mean(),\n",
    "        'rmse_std': neg_rmse_scores.std(),\n",
    "        'mae_mean': -neg_mae_scores.mean(),\n",
    "        'mae_std': neg_mae_scores.std(),\n",
    "        'r2_mean': r2_scores.mean(),\n",
    "        'r2_std': r2_scores.std(),\n",
    "    }\n",
    "    \n",
    "    all_results['CatBoost'] = cat_results\n",
    "    \n",
    "    print(f\"\\nCross-Validation Results:\")\n",
    "    print(f\"  RMSE: {cat_results['rmse_mean']:,.2f} (+/- {cat_results['rmse_std']:,.2f})\")\n",
    "    print(f\"  MAE:  {cat_results['mae_mean']:,.2f} (+/- {cat_results['mae_std']:,.2f})\")\n",
    "    print(f\"  R²:   {cat_results['r2_mean']:.4f} (+/- {cat_results['r2_std']:.4f})\")\n",
    "else:\n",
    "    print(\"CatBoost not available. Install with: pip install catboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison = compare_models(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON (sorted by RMSE)\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RMSE\n",
    "ax = axes[0]\n",
    "ax.barh(comparison['Model'], comparison['rmse_mean'], xerr=comparison['rmse_std'], capsize=5)\n",
    "ax.set_xlabel('RMSE (€)')\n",
    "ax.set_title('RMSE by Model')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# MAE\n",
    "ax = axes[1]\n",
    "ax.barh(comparison['Model'], comparison['mae_mean'], xerr=comparison['mae_std'], capsize=5, color='orange')\n",
    "ax.set_xlabel('MAE (€)')\n",
    "ax.set_title('MAE by Model')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# R²\n",
    "ax = axes[2]\n",
    "ax.barh(comparison['Model'], comparison['r2_mean'], xerr=comparison['r2_std'], capsize=5, color='green')\n",
    "ax.set_xlabel('R²')\n",
    "ax.set_title('R² by Model')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 6. Train Best Model on Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model based on RMSE\n",
    "best_model_name = comparison.iloc[0]['Model']\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "# Train on full training data\n",
    "if best_model_name == 'CatBoost' and CATBOOST_AVAILABLE:\n",
    "    # Train CatBoost\n",
    "    final_model = build_catboost_model(categorical_cols, loss_function='RMSE')\n",
    "    final_model.fit(X_cb_train, y_cb_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = final_model.predict(X_cb_test)\n",
    "    final_metrics = evaluate_predictions(y_cb_test, y_pred)\n",
    "    \n",
    "    # Feature columns for metadata\n",
    "    model_feature_cols = list(X_cb.columns)\n",
    "    \n",
    "else:\n",
    "    # Train sklearn model\n",
    "    model_type_map = {\n",
    "        'Random Forest': 'random_forest',\n",
    "        'HistGradientBoosting': 'hist_gradient_boosting',\n",
    "        'Baseline (Mean)': 'dummy'\n",
    "    }\n",
    "    model_type = model_type_map.get(best_model_name, 'random_forest')\n",
    "    \n",
    "    final_model = build_sklearn_pipeline(model_type, numeric_cols, categorical_cols)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    final_metrics = evaluate_predictions(y_test, y_pred)\n",
    "    \n",
    "    model_feature_cols = feature_cols\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  RMSE: {final_metrics['rmse']:,.2f}\")\n",
    "print(f\"  MAE:  {final_metrics['mae']:,.2f}\")\n",
    "print(f\"  R²:   {final_metrics['r2']:.4f}\")\n",
    "print(f\"  MAPE: {final_metrics['mape']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 7. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Get the right y values\n",
    "if best_model_name == 'CatBoost' and CATBOOST_AVAILABLE:\n",
    "    y_actual = y_cb_test\n",
    "else:\n",
    "    y_actual = y_test\n",
    "\n",
    "# Scatter plot\n",
    "ax = axes[0]\n",
    "ax.scatter(y_actual, y_pred, alpha=0.3, s=10)\n",
    "ax.plot([0, y_actual.max()], [0, y_actual.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual Price (€)')\n",
    "ax.set_ylabel('Predicted Price (€)')\n",
    "ax.set_title('Actual vs Predicted Prices')\n",
    "ax.legend()\n",
    "\n",
    "# Residuals\n",
    "ax = axes[1]\n",
    "residuals = y_actual - y_pred\n",
    "ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='red', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Residual (€)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Residual Distribution (Mean: {residuals.mean():,.0f}€, Std: {residuals.std():,.0f}€)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error by price range\n",
    "results_df = pd.DataFrame({\n",
    "    'actual': y_actual,\n",
    "    'predicted': y_pred,\n",
    "    'error': np.abs(y_actual - y_pred),\n",
    "    'pct_error': np.abs(y_actual - y_pred) / y_actual * 100\n",
    "})\n",
    "\n",
    "# Price bins\n",
    "results_df['price_bin'] = pd.cut(results_df['actual'], \n",
    "                                  bins=[0, 500, 1000, 1500, 2000, 3000, 10000],\n",
    "                                  labels=['0-500', '500-1000', '1000-1500', '1500-2000', '2000-3000', '3000+'])\n",
    "\n",
    "# Stats by price range\n",
    "print(\"=== Error by Price Range ===\")\n",
    "error_by_range = results_df.groupby('price_bin', observed=True).agg({\n",
    "    'actual': 'count',\n",
    "    'error': ['mean', 'std'],\n",
    "    'pct_error': 'mean'\n",
    "}).round(2)\n",
    "error_by_range.columns = ['Count', 'MAE (€)', 'Std (€)', 'MAPE (%)']\n",
    "display(error_by_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 8. CatBoost Quantile Regression (Price Range Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CATBOOST_AVAILABLE:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"QUANTILE REGRESSION (Price Range Prediction)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train models for different quantiles\n",
    "    quantiles = [0.1, 0.5, 0.9]\n",
    "    quantile_models = {}\n",
    "    \n",
    "    for q in quantiles:\n",
    "        print(f\"\\nTraining quantile={q} model...\")\n",
    "        q_model = build_catboost_model(categorical_cols, loss_function='Quantile', quantile=q)\n",
    "        q_model.fit(X_cb_train, y_cb_train)\n",
    "        quantile_models[q] = q_model\n",
    "    \n",
    "    # Predict on test set\n",
    "    pred_low = quantile_models[0.1].predict(X_cb_test)\n",
    "    pred_mid = quantile_models[0.5].predict(X_cb_test)\n",
    "    pred_high = quantile_models[0.9].predict(X_cb_test)\n",
    "    \n",
    "    # Check coverage\n",
    "    in_range = (y_cb_test >= pred_low) & (y_cb_test <= pred_high)\n",
    "    coverage = in_range.mean() * 100\n",
    "    \n",
    "    print(f\"\\n=== Quantile Prediction Results ===\")\n",
    "    print(f\"Expected coverage (10%-90% interval): 80%\")\n",
    "    print(f\"Actual coverage: {coverage:.1f}%\")\n",
    "    print(f\"Average interval width: {(pred_high - pred_low).mean():,.0f}€\")\n",
    "else:\n",
    "    print(\"CatBoost not available - skipping quantile regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CATBOOST_AVAILABLE:\n",
    "    # Visualize quantile predictions\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Sample for visualization\n",
    "    sample_idx = np.random.choice(len(y_cb_test), min(100, len(y_cb_test)), replace=False)\n",
    "    sample_idx = np.sort(sample_idx)\n",
    "    \n",
    "    x_pos = np.arange(len(sample_idx))\n",
    "    \n",
    "    # Plot intervals\n",
    "    ax.fill_between(x_pos, pred_low.values[sample_idx], pred_high.values[sample_idx], \n",
    "                    alpha=0.3, label='80% Prediction Interval')\n",
    "    ax.scatter(x_pos, y_cb_test.values[sample_idx], c='red', s=20, label='Actual', zorder=5)\n",
    "    ax.plot(x_pos, pred_mid[sample_idx], 'b-', lw=1, label='Median Prediction', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('Price (€)')\n",
    "    ax.set_title('Price Predictions with Uncertainty Intervals')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model with metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'feature_cols': model_feature_cols,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'target_col': TARGET_COL,\n",
    "    'test_metrics': final_metrics,\n",
    "    'cv_metrics': all_results.get(best_model_name, {}),\n",
    "}\n",
    "\n",
    "save_model(final_model, '../models/price_model.pkl', metadata)\n",
    "\n",
    "print(f\"\\nModel saved with metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    if key in ['feature_cols', 'numeric_cols', 'categorical_cols']:\n",
    "        print(f\"  {key}: {len(value)} columns\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Results\n",
    "\n",
    "We trained and compared multiple models for predicting computer prices:\n",
    "\n",
    "1. **Baseline** - Simple mean prediction\n",
    "2. **Random Forest** - Ensemble of decision trees\n",
    "3. **HistGradientBoosting** - sklearn's fast gradient boosting\n",
    "4. **CatBoost** - Native categorical handling (if available)\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- Best model saved to `models/price_model.pkl`\n",
    "- Quantile regression enables price range predictions\n",
    "- Error varies by price range (larger absolute errors for expensive items)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Feature selection to reduce complexity\n",
    "2. Hyperparameter tuning\n",
    "3. Deploy model via backend API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
