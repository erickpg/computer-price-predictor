{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - EDA: Computer Marketplace Dataset\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook performs an initial exploration of `db_computers_2025_raw.csv` - a dataset of computer listings from a marketplace.\n",
    "\n",
    "### Goals\n",
    "\n",
    "1. **Understand the target variable** (price) - its distribution, range, and potential transformations\n",
    "2. **Inspect distributions and missing values** across all columns\n",
    "3. **Identify core features** for the initial model:\n",
    "   - Product type (Tipo de producto)\n",
    "   - Brand (Marca) and Series (Serie)\n",
    "   - Processor (Procesador_Procesador)\n",
    "   - Graphics card (Gráfica_Tarjeta gráfica)\n",
    "   - RAM, storage, screen specs\n",
    "4. **Prepare observations** for the feature engineering notebook\n",
    "\n",
    "### Important Conventions\n",
    "\n",
    "- **Original Spanish column names are preserved** - we do NOT rename or translate columns\n",
    "- All comments and markdown are in English for readability\n",
    "- Engineered features (created in later notebooks) will start with underscore: `_cpu_mark`, `_ram_gb`, etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_theme(style='whitegrid', palette='deep')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths (relative to notebooks/ folder)\n",
    "DATA_DIR = Path('../data')\n",
    "\n",
    "# Main dataset\n",
    "computers_path = DATA_DIR / 'db_computers_2025_raw.csv'\n",
    "columns_info_path = DATA_DIR / 'db_computers_columns_names.txt'\n",
    "\n",
    "# Load the main dataset\n",
    "# Note: Using utf-8-sig to handle BOM, index_col=0 then reset_index per course instructions\n",
    "df = pd.read_csv(\n",
    "    computers_path,\n",
    "    encoding='utf-8-sig',\n",
    "    index_col=0\n",
    ").reset_index()\n",
    "\n",
    "# Rename the old index column if needed\n",
    "if 'index' in df.columns:\n",
    "    df = df.rename(columns={'index': 'id_original'})\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"  - Rows (computer listings): {df.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first few rows\n",
    "# Note: Original Spanish column names are preserved exactly as they appear in the CSV\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all columns to see what's available\n",
    "print(\"All columns in the dataset:\\n\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:3d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Info and Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic info about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values for key categorical columns\n",
    "# These are columns we suspect will be important for prediction\n",
    "\n",
    "key_columns = [\n",
    "    'Tipo de producto',           # Product type (laptop, desktop, etc.)\n",
    "    'Serie',                       # Product series/line\n",
    "    'Tipo',                        # Type (Laptop, etc.)\n",
    "    'Procesador_Fabricante del procesador',  # CPU manufacturer (Intel, AMD, Apple)\n",
    "    'Gráfica_Fabricante de la tarjeta gráfica',  # GPU manufacturer\n",
    "    'Sistema operativo_Sistema operativo',  # OS\n",
    "]\n",
    "\n",
    "print(\"Unique value counts for key categorical columns:\\n\")\n",
    "for col in key_columns:\n",
    "    if col in df.columns:\n",
    "        print(f\"{col}:\")\n",
    "        print(f\"  Unique values: {df[col].nunique()}\")\n",
    "        print(f\"  Missing: {df[col].isna().sum()} ({df[col].isna().mean()*100:.1f}%)\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for product type - this is crucial for understanding our dataset\n",
    "if 'Tipo de producto' in df.columns:\n",
    "    print(\"Product types (Tipo de producto):\\n\")\n",
    "    print(df['Tipo de producto'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for 'Tipo' column\n",
    "if 'Tipo' in df.columns:\n",
    "    print(\"Type (Tipo):\\n\")\n",
    "    print(df['Tipo'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU manufacturers\n",
    "if 'Procesador_Fabricante del procesador' in df.columns:\n",
    "    print(\"CPU Manufacturers (Procesador_Fabricante del procesador):\\n\")\n",
    "    print(df['Procesador_Fabricante del procesador'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Exploration: Price (Precio)\n",
    "\n",
    "The price information is stored in the `Precio_Rango` column as a string range (e.g., \"1.026,53 € – 2.287,17 €\").\n",
    "\n",
    "For modeling, we'll need to extract a numeric value from this range. For now, let's explore it as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the price column\n",
    "precio_col = 'Precio_Rango'\n",
    "\n",
    "print(f\"Price column: {precio_col}\")\n",
    "print(f\"\\nSample values:\")\n",
    "print(df[precio_col].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_precio_numerico(precio_str):\n",
    "    \"\"\"\n",
    "    Extract numeric price from a range string.\n",
    "    For ranges like \"1.026,53 € – 2.287,17 €\", returns the midpoint.\n",
    "    For single prices, returns that price.\n",
    "    \n",
    "    Spanish format: periods for thousands, commas for decimals.\n",
    "    \"\"\"\n",
    "    if pd.isna(precio_str) or not isinstance(precio_str, str):\n",
    "        return np.nan\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    # Find all price patterns (number with Spanish format)\n",
    "    # Pattern: digits with optional periods, comma, digits\n",
    "    pattern = r'([\\d.]+,\\d{2})'\n",
    "    matches = re.findall(pattern, precio_str)\n",
    "    \n",
    "    if not matches:\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert Spanish format to float\n",
    "    precios = []\n",
    "    for m in matches:\n",
    "        # Remove thousand separators (.), replace decimal comma with period\n",
    "        num_str = m.replace('.', '').replace(',', '.')\n",
    "        precios.append(float(num_str))\n",
    "    \n",
    "    # Return midpoint if range, otherwise single value\n",
    "    if len(precios) == 2:\n",
    "        return (precios[0] + precios[1]) / 2\n",
    "    elif len(precios) == 1:\n",
    "        return precios[0]\n",
    "    else:\n",
    "        return np.mean(precios)\n",
    "\n",
    "# Extract numeric prices (for EDA only - proper extraction in features.py)\n",
    "df['_precio_eda'] = df[precio_col].apply(extraer_precio_numerico)\n",
    "\n",
    "print(f\"Extracted numeric prices:\")\n",
    "print(f\"  Valid prices: {df['_precio_eda'].notna().sum()} / {len(df)}\")\n",
    "print(f\"  Missing: {df['_precio_eda'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price statistics\n",
    "print(\"Price Statistics (in €):\\n\")\n",
    "print(df['_precio_eda'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "df['_precio_eda'].hist(bins=50, ax=ax1, edgecolor='black', alpha=0.7)\n",
    "ax1.set_xlabel('Price (€)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Price Distribution (Histogram)')\n",
    "ax1.axvline(df['_precio_eda'].median(), color='red', linestyle='--', label=f\"Median: {df['_precio_eda'].median():,.0f}€\")\n",
    "ax1.axvline(df['_precio_eda'].mean(), color='orange', linestyle='--', label=f\"Mean: {df['_precio_eda'].mean():,.0f}€\")\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "ax2 = axes[1]\n",
    "df.boxplot(column='_precio_eda', ax=ax2)\n",
    "ax2.set_ylabel('Price (€)')\n",
    "ax2.set_title('Price Distribution (Box Plot)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observations on price distribution\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- The distribution appears right-skewed (long tail of high prices)\")\n",
    "print(\"- There are potential outliers at the high end (expensive gaming/workstation PCs)\")\n",
    "print(\"- A log-transform might help normalize the distribution for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transformed price distribution (preview for future consideration)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "df['_log_precio'] = np.log1p(df['_precio_eda'])\n",
    "df['_log_precio'].hist(bins=50, ax=ax, edgecolor='black', alpha=0.7, color='green')\n",
    "ax.set_xlabel('Log(Price + 1)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Log-Transformed Price Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Log-transform makes the distribution more symmetric.\")\n",
    "print(\"Consider using log-price as target, then exp() to get final predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Missing Values Overview\n",
    "\n",
    "Understanding missing values is crucial for:\n",
    "- Deciding which features to include in the model\n",
    "- Choosing imputation strategies\n",
    "- Identifying potentially unreliable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values per column\n",
    "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "\n",
    "# Create a summary DataFrame\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing %': missing_pct,\n",
    "    'Present %': 100 - missing_pct\n",
    "})\n",
    "\n",
    "# Show columns with most missing values\n",
    "print(\"Columns with MOST missing values (top 30):\\n\")\n",
    "print(missing_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show columns with LEAST missing values (most complete)\n",
    "print(\"Columns with LEAST missing values (most complete):\\n\")\n",
    "print(missing_df.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values for key feature columns\n",
    "# Focus on columns we expect to use for modeling\n",
    "\n",
    "key_feature_cols = [\n",
    "    'Precio_Rango',\n",
    "    'Título',\n",
    "    'Tipo de producto',\n",
    "    'Serie',\n",
    "    'Procesador_Procesador',\n",
    "    'Procesador_Fabricante del procesador',\n",
    "    'Procesador_Número de núcleos del procesador',\n",
    "    'RAM_Memoria RAM',\n",
    "    'RAM_Tipo de RAM',\n",
    "    'Disco duro_Capacidad de memoria SSD',\n",
    "    'Disco duro_Tipo de disco duro',\n",
    "    'Gráfica_Tarjeta gráfica',\n",
    "    'Gráfica_Fabricante de la tarjeta gráfica',\n",
    "    'Gráfica_Memoria gráfica',\n",
    "    'Pantalla_Diagonal de la pantalla',\n",
    "    'Pantalla_Resolución de pantalla',\n",
    "    'Tipo',\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "key_feature_cols = [c for c in key_feature_cols if c in df.columns]\n",
    "\n",
    "key_missing = missing_df.loc[key_feature_cols].sort_values('Missing %', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "key_missing['Present %'].plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_xlabel('Data Completeness (%)')\n",
    "ax.set_title('Data Completeness for Key Feature Columns')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add percentage labels\n",
    "for i, v in enumerate(key_missing['Present %']):\n",
    "    ax.text(v + 1, i, f'{v:.1f}%', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize columns by missing data levels\n",
    "very_sparse = missing_df[missing_df['Missing %'] >= 80].index.tolist()  # >80% missing\n",
    "sparse = missing_df[(missing_df['Missing %'] >= 50) & (missing_df['Missing %'] < 80)].index.tolist()\n",
    "moderate = missing_df[(missing_df['Missing %'] >= 20) & (missing_df['Missing %'] < 50)].index.tolist()\n",
    "dense = missing_df[missing_df['Missing %'] < 20].index.tolist()  # <20% missing\n",
    "\n",
    "print(f\"Very Sparse (>80% missing): {len(very_sparse)} columns\")\n",
    "print(f\"Sparse (50-80% missing): {len(sparse)} columns\")\n",
    "print(f\"Moderate (20-50% missing): {len(moderate)} columns\")\n",
    "print(f\"Dense (<20% missing): {len(dense)} columns\")\n",
    "\n",
    "print(\"\\n--- Dense columns (likely useful for initial model) ---\")\n",
    "for col in dense:\n",
    "    print(f\"  {col}: {missing_df.loc[col, 'Present %']:.1f}% present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Observations\n",
    "\n",
    "**Dense columns (low missingness, likely useful):**\n",
    "- `Título` (Title) - Always present, can extract brand info\n",
    "- `Precio_Rango` - Target variable, mostly present\n",
    "- `Tipo de producto` - Product category (gaming, multimedia, etc.)\n",
    "- `Tipo` - Laptop vs Desktop classification\n",
    "\n",
    "**Moderate missingness (need imputation):**\n",
    "- `Procesador_Procesador` - CPU name, will need fuzzy matching to benchmarks\n",
    "- `RAM_Memoria RAM` - RAM info, extractable with regex\n",
    "- Screen-related columns\n",
    "\n",
    "**Sparse columns (might drop or use carefully):**\n",
    "- Many detailed spec columns are very sparse\n",
    "- Some columns only apply to specific product types (e.g., battery for laptops only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. First Thoughts on Core Features\n",
    "\n",
    "Based on domain knowledge about computer pricing, here are the features we expect to be most predictive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core features we plan to use for the initial model\n",
    "# Note: We'll create engineered versions of many of these with _ prefix\n",
    "\n",
    "posibles_features_core = [\n",
    "    # Category/Type\n",
    "    'Tipo de producto',           # Product type (gaming, multimedia, professional)\n",
    "    'Tipo',                        # Laptop vs Desktop\n",
    "    'Serie',                       # Product series (often indicates tier)\n",
    "    \n",
    "    # Processor\n",
    "    'Procesador_Procesador',       # CPU model - will map to _cpu_mark benchmark\n",
    "    'Procesador_Fabricante del procesador',  # Intel, AMD, Apple\n",
    "    'Procesador_Número de núcleos del procesador',  # Core count\n",
    "    \n",
    "    # Graphics\n",
    "    'Gráfica_Tarjeta gráfica',     # GPU model - will map to _gpu_mark benchmark\n",
    "    'Gráfica_Fabricante de la tarjeta gráfica',  # NVIDIA, AMD, Intel\n",
    "    'Gráfica_Memoria gráfica',     # VRAM\n",
    "    \n",
    "    # Memory and Storage\n",
    "    'RAM_Memoria RAM',             # RAM - will extract to _ram_gb\n",
    "    'RAM_Tipo de RAM',             # DDR4, DDR5, LPDDR5X\n",
    "    'Disco duro_Capacidad de memoria SSD',  # SSD - will extract to _ssd_gb\n",
    "    'Disco duro_Tipo de disco duro',  # SSD, HDD, hybrid\n",
    "    \n",
    "    # Display\n",
    "    'Pantalla_Diagonal de la pantalla',  # Screen size - will extract to _tamano_pantalla_pulgadas\n",
    "    'Pantalla_Resolución de pantalla',   # Resolution\n",
    "    'Pantalla_Tasa de actualización de imagen',  # Refresh rate (important for gaming)\n",
    "]\n",
    "\n",
    "print(\"Core features for initial model:\")\n",
    "for i, feat in enumerate(posibles_features_core, 1):\n",
    "    if feat in df.columns:\n",
    "        present_pct = (1 - df[feat].isna().mean()) * 100\n",
    "        print(f\"{i:2d}. {feat}: {present_pct:.1f}% present\")\n",
    "    else:\n",
    "        print(f\"{i:2d}. {feat}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore RAM column\n",
    "print(\"RAM_Memoria RAM - Value distribution:\\n\")\n",
    "if 'RAM_Memoria RAM' in df.columns:\n",
    "    print(df['RAM_Memoria RAM'].value_counts(dropna=False).head(20))\n",
    "    print(\"\\n-> RAM seems mostly present, values like '16 GB RAM', '8 GB RAM', etc.\")\n",
    "    print(\"-> Will need to extract numeric value to _ram_gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore processor column\n",
    "print(\"Procesador_Procesador - Sample values:\\n\")\n",
    "if 'Procesador_Procesador' in df.columns:\n",
    "    print(df['Procesador_Procesador'].value_counts(dropna=False).head(20))\n",
    "    print(\"\\n-> Many unique CPU models (Intel Core i7-13700H, AMD Ryzen 7, Apple M3, etc.)\")\n",
    "    print(\"-> Will need to map to benchmark scores using db_cpu_raw.csv and fuzzy matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore GPU column\n",
    "print(\"Gráfica_Tarjeta gráfica - Sample values:\\n\")\n",
    "if 'Gráfica_Tarjeta gráfica' in df.columns:\n",
    "    print(df['Gráfica_Tarjeta gráfica'].value_counts(dropna=False).head(20))\n",
    "    print(\"\\n-> Some GPU fields are sparse (integrated graphics often not listed)\")\n",
    "    print(\"-> Will need fuzzy matching to db_gpu_raw.csv for _gpu_mark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore SSD capacity column\n",
    "print(\"Disco duro_Capacidad de memoria SSD - Sample values:\\n\")\n",
    "if 'Disco duro_Capacidad de memoria SSD' in df.columns:\n",
    "    print(df['Disco duro_Capacidad de memoria SSD'].value_counts(dropna=False).head(20))\n",
    "    print(\"\\n-> Values like '512 GB', '1.000 GB', '256 GB'\")\n",
    "    print(\"-> Will extract to numeric _ssd_gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore screen size column\n",
    "print(\"Pantalla_Diagonal de la pantalla - Sample values:\\n\")\n",
    "if 'Pantalla_Diagonal de la pantalla' in df.columns:\n",
    "    print(df['Pantalla_Diagonal de la pantalla'].value_counts(dropna=False).head(15))\n",
    "    print(\"\\n-> Values in cm like '39,624 cm', '35,56 cm'\")\n",
    "    print(\"-> Will convert to inches for _tamano_pantalla_pulgadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by product type - initial exploration\n",
    "if 'Tipo de producto' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Filter to types with enough samples\n",
    "    tipo_counts = df['Tipo de producto'].value_counts()\n",
    "    main_tipos = tipo_counts[tipo_counts >= 10].index\n",
    "    \n",
    "    df_plot = df[df['Tipo de producto'].isin(main_tipos)]\n",
    "    \n",
    "    df_plot.boxplot(column='_precio_eda', by='Tipo de producto', ax=ax)\n",
    "    ax.set_xlabel('Tipo de producto')\n",
    "    ax.set_ylabel('Price (€)')\n",
    "    ax.set_title('Price Distribution by Product Type')\n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nObservation: Gaming laptops (Portátil gaming) tend to have higher prices.\")\n",
    "    print(\"Product type will be an important categorical feature.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Dataset Size**: The dataset contains computer listings with ~140+ columns covering detailed specifications.\n",
    "\n",
    "2. **Target Variable (Price)**:\n",
    "   - Stored as a price range string in `Precio_Rango`\n",
    "   - Right-skewed distribution with outliers at high end\n",
    "   - Log-transform may help for modeling\n",
    "   - Need to extract numeric value for `_precio_num`\n",
    "\n",
    "3. **Missing Values**:\n",
    "   - Many columns are very sparse (>80% missing)\n",
    "   - Core columns like `Título`, `Tipo de producto`, `Precio_Rango` are mostly complete\n",
    "   - Will need imputation strategy for moderately-sparse features\n",
    "\n",
    "4. **Core Features Identified**:\n",
    "   - **Product category**: `Tipo de producto`, `Tipo`, `Serie`\n",
    "   - **Processor**: `Procesador_Procesador` → needs benchmark matching\n",
    "   - **Graphics**: `Gráfica_Tarjeta gráfica` → needs benchmark matching\n",
    "   - **Memory**: `RAM_Memoria RAM` → extract numeric GB\n",
    "   - **Storage**: `Disco duro_Capacidad de memoria SSD` → extract numeric GB\n",
    "   - **Screen**: `Pantalla_Diagonal de la pantalla` → convert to inches\n",
    "\n",
    "5. **Key Observations**:\n",
    "   - Gaming laptops (`Portátil gaming`) have higher prices\n",
    "   - CPU/GPU models are varied and will need fuzzy matching to benchmark data\n",
    "   - Many numeric values stored as strings with Spanish format (comma decimal)\n",
    "\n",
    "### Open Questions\n",
    "\n",
    "1. How to handle computers with integrated graphics (no dedicated GPU)?\n",
    "2. Should we model different product types separately or together?\n",
    "3. Which sparse columns are still worth including with careful imputation?\n",
    "4. How to extract brand from title when `Marca` column is missing?\n",
    "\n",
    "---\n",
    "\n",
    "### Next Notebook: `02_feature_engineering.ipynb`\n",
    "\n",
    "In the next notebook, we will:\n",
    "\n",
    "1. **Create engineered features** using `src/features.py`:\n",
    "   - `_precio_num`: Numeric price (midpoint of range)\n",
    "   - `_cpu_mark`: CPU benchmark score from `db_cpu_raw.csv`\n",
    "   - `_gpu_mark`: GPU benchmark score from `db_gpu_raw.csv`\n",
    "   - `_ram_gb`: RAM in GB (numeric)\n",
    "   - `_ssd_gb`: SSD capacity in GB (numeric)\n",
    "   - `_tamano_pantalla_pulgadas`: Screen size in inches\n",
    "\n",
    "2. **Implement missing value strategy**:\n",
    "   - Decide which columns to keep vs drop\n",
    "   - Choose imputation methods (median, mode, constant)\n",
    "\n",
    "3. **Prepare clean feature table** for modeling (notebook 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Remove temporary columns created for EDA\n",
    "eda_cols = ['_precio_eda', '_log_precio']\n",
    "for col in eda_cols:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "print(\"EDA notebook complete!\")\n",
    "print(f\"Next: 02_feature_engineering.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
